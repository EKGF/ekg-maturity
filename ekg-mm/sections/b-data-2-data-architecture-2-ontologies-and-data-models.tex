\section{Ontologies \& Data Models}\label{sec:ekgmm-b-2-2} % B.2.2 Ontologies and Data Models

Data modeling is a formal process designed to describe the data needed to support the business functions within
an organization.
Effective data modeling is a communications mechanism to ensure a shared understanding of requirements between
business stakeholders and applications developers.
Data modeling (via either ontology design or more traditional techniques) results in agreed terminology, precise
definitions and alignment of the models to applicable business rules.

\kgmmekgrationalesection

Well-designed data models describe what the data means as well as how concepts are connected.
Conceptual data models include the expression of high-level concepts and capture business rules to provide a starting
point for the development of operational ontologies.
These conceptual models should link to business glossaries and be directly translated into physical data structures.
The link to precise meaning serves to mitigate problems created using the same word with multiple definitions and
the challenges of expressing conceptual nuance using a variety of words.

Semantic modeling also eliminates the problem of hard-coding assumptions about the world into a single data model.
And while multiple models may co-exist, they are able to be mapped and connected to each other.
In a mature environment, the data modelling process drives technology implementation, by defining the detailed
data structures and associated APIs.
These components (along with functional code) are included as part of the testing suite within the knowledge graph
to facilitate rapid deployment.

\kgmmcorequestionssection

\begin{core-questions}

  \item [\thesection.1] Which areas of the business use well-defined data models
  \item [\thesection.2] Are the data models of the organization linked to the business glossary
  \item [\thesection.3] Are the data models directly linked to the data structures of the consuming applications'
                        data structures
  \item [\thesection.4] How are data models synchronized and aligned across the organization
  \item [\thesection.5] How are the links between data modeling and systems implementation approved and tested
                        (i.e. standard process for approval, change management logs)
  \item [\thesection.6] Are the models used to generate code-specific artifacts (i.e. APIs)
  \item [\thesection.7] Are the data models searchable from the corporate intranet
  \item [\thesection.8] Can the adoption of shared meaning be demonstrated and verified by audit
  \item [\thesection.9] Is the organization using (or mapping to) industry-standard reference points to
                        accelerate development

\end{core-questions}

\begin{members-only}

\kgmmscoringsection

\kgmmscoringlevelOne

\begin{scoring}

  \item [meaning] The granular business meaning of all onboarded data from source systems is verified by SMEs and
        captured as an ontology (machine-readable; every property has its predicate-IRI)
  \item [implementation] Ensure that all onboarded data is tagged with the predicate-IRIs
  \item [basic ontology structure] Define and agree use case specific (target) ontologies for expressing shared and
        foundational concepts [practical target ontologies to support data mapping, harmonization and lineage]
  \item [mapping] Apply transformations from source-to-target ontologies (convert ETL pipeline to standard ontologies)\todo{rephrase}
  \item [governance] Implement governance process for ontology ownership and maintenance (must have responsible parties
        for each domain to facilitate approvals and support change management)
  \item [testing] Implement automated testing and validation of ontologies (per use case) - logical structure, coverage,
        no circular reasoning
  \item [testing] Every change to any ontology and every mapping must be tested (thou shalt never do anything if it
        cannot be tested)
  \item [DevOps] Implement the DevOps environment for ontology lifecycle management with source and version control
        (i.e. Git) - every change will be in Git and tested - do it right from the beginning

\end{scoring}

\kgmmscoringlevelTwo

\begin{scoring}

  \item [enhanced ontologies] Enhance target ontologies with \iindex{OWL axioms}, \gls{bitemporality}, to support
        transactions and events (for reasoning)
  \item [reasoning] Develop upper ontologies and abstractions for shared concepts (prepare for reasoning capabilities
        as a building block)
  \item Domain taxonomies are created and annotated to use cases and related ontologies (must know what ontologies
        exist and for which domain they are targeted)
  \item [governance] Onboard governance activities (full audit trail on changes and approvals) into the knowledge graph
  \item [testing] Onboard all test scripts and validation of tests into the knowledge graph for quality assurance ranking
  \item [architecture governance] Develop and agree to process for ontology policies and codification of architectural
        decisions and patterns

\end{scoring}

\TODO[inline]{Finish scoring levels for EKG/MM capability level 3 and higher}

\end{members-only}

